Brian C. Pike's Wine List Classifier
========================================================

wine = read.csv("http://www.nd.edu/~mclark19/learn/data/goodwine.csv")
summary(wine)
 fixed.acidity    volatile.acidity  citric.acid     residual.sugar     chlorides       free.sulfur.dioxide total.sulfur.dioxide    density             pH          sulphates     
 Min.   : 3.800   Min.   :0.0800   Min.   :0.0000   Min.   : 0.600   Min.   :0.00900   Min.   :  1.00      Min.   :  6.0        Min.   :0.9871   Min.   :2.720   Min.   :0.2200  
 1st Qu.: 6.400   1st Qu.:0.2300   1st Qu.:0.2500   1st Qu.: 1.800   1st Qu.:0.03800   1st Qu.: 17.00      1st Qu.: 77.0        1st Qu.:0.9923   1st Qu.:3.110   1st Qu.:0.4300  
 Median : 7.000   Median :0.2900   Median :0.3100   Median : 3.000   Median :0.04700   Median : 29.00      Median :118.0        Median :0.9949   Median :3.210   Median :0.5100  
 Mean   : 7.215   Mean   :0.3397   Mean   :0.3186   Mean   : 5.443   Mean   :0.05603   Mean   : 30.53      Mean   :115.7        Mean   :0.9947   Mean   :3.219   Mean   :0.5313  
 3rd Qu.: 7.700   3rd Qu.:0.4000   3rd Qu.:0.3900   3rd Qu.: 8.100   3rd Qu.:0.06500   3rd Qu.: 41.00      3rd Qu.:156.0        3rd Qu.:0.9970   3rd Qu.:3.320   3rd Qu.:0.6000  
 Max.   :15.900   Max.   :1.5800   Max.   :1.6600   Max.   :65.800   Max.   :0.61100   Max.   :289.00      Max.   :440.0        Max.   :1.0390   Max.   :4.010   Max.   :2.0000  
    alcohol         quality        color          white          good     
 Min.   : 8.00   Min.   :3.000   red  :1599   Min.   :0.0000   Bad :2384  
 1st Qu.: 9.50   1st Qu.:5.000   white:4898   1st Qu.:1.0000   Good:4113  
 Median :10.30   Median :6.000                Median :1.0000              
 Mean   :10.49   Mean   :5.818                Mean   :0.7539              
 3rd Qu.:11.30   3rd Qu.:6.000                3rd Qu.:1.0000              
 Max.   :14.90   Max.   :9.000                Max.   :1.0000          

library(corrplot)
corrplot(cor(wine[, -c(13, 15)]), method = "number", tl.cex = 0.5)
 
library(caret)
set.seed(1234) #so that the indices will be the same when re-run
trainIndices = createDataPartition(wine$good, p = 0.8, list = F)
wanted = !colnames(wine) %in% c("free.sulfur.dioxide", "density", "quality",
+                                 "color", "white")
wine_train = wine[trainIndices, wanted] #remove quality and color, as well as density and others
wine_test = wine[-trainIndices, wanted]

wine_trainplot = predict(preProcess(wine_train[,-10], method="range"),
+                          wine_train[,-10])
featurePlot(wine_trainplot, wine_train$good, "box")

library("e1071")
set.seed(1234)
cv_opts = trainControl(method="cv", number=10)
knn_opts = data.frame(.k=c(seq(3, 11, 2), 25, 51, 101)) #odd to avoid ties
results_knn = train(good~., data=wine_train, method="knn",
+                     preProcess="range", trControl=cv_opts,
+                     tuneGrid = knn_opts) 

results_knn
k-Nearest Neighbors 

5199 samples
   9 predictors
   2 classes: 'Bad', 'Good' 

Pre-processing: re-scaling to [0, 1] 
Resampling: Cross-Validated (10 fold) 

Summary of sample sizes: 4679, 4679, 4680, 4679, 4679, 4679, ... 

Resampling results across tuning parameters:

  k    Accuracy  Kappa  Accuracy SD  Kappa SD
  3    0.752     0.458  0.0198       0.0448  
  5    0.746     0.442  0.0116       0.0274  
  7    0.75      0.448  0.0186       0.0424  
  9    0.747     0.441  0.0152       0.0353  
  11   0.747     0.442  0.017        0.0369  
  25   0.749     0.442  0.0179       0.0415  
  51   0.744     0.428  0.0178       0.0407  
  101  0.742     0.418  0.0183       0.0423  

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was k = 3. 


preds_knn = predict(results_knn, wine_test[,-10])
confusionMatrix(preds_knn, wine_test[,10], positive='Good')
Confusion Matrix and Statistics

          Reference
Prediction Bad Good
      Bad  281  164
      Good 195  658
                                          
               Accuracy : 0.7234          
                 95% CI : (0.6982, 0.7476)
    No Information Rate : 0.6333          
    P-Value [Acc > NIR] : 3.708e-12       
                                          
                  Kappa : 0.3963          
 Mcnemar's Test P-Value : 0.1133          
                                          
            Sensitivity : 0.8005          
            Specificity : 0.5903          
         Pos Pred Value : 0.7714          
         Neg Pred Value : 0.6315          
             Prevalence : 0.6333          
         Detection Rate : 0.5069          
   Detection Prevalence : 0.6572          
      Balanced Accuracy : 0.6954          
                                          
       'Positive' Class : Good            